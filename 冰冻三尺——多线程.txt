多线程：
	http://ifeve.com/java-memory-model-1/

    1.volatile关键字，可以保证变量在线程间的共享性，不能保证原子性。
	volatile能保证共享性是因为，添加了volatile的关键字会迫使线程每次使用该变量的时候从主内存中更新数据。
	理解volatile特性的一个好方法是：把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。
	对一个volatile变量的单个读/写操作，与对一个普通变量的读/写操作使用同一个锁来同步，它们之间的执行效果相同。
	
	例：i++的问题。java的所有实例，静态域和数组元素都是保存在堆内存里面的。堆内存相当于主内存。
	每个线程都有自己的工作内存，线程在操作堆内存中的内容时，会先从主内存中复制数据到自己的工作内存，
	处理完成之后，在将工作内存中的数据覆盖到主内存中。
	i++在JVM内部被拆解成三个步骤：1.从主内存拷贝数据到本地内存；2.将i的值加1；3.将i的值覆盖到主内存中去
	如果一个线程执行了第一步和第二步，还没有执行第三步的时候，另一个线程抢到cup的使用权，也从主内存中拷贝了
	i的值到自己的本地内存，就会出现原子性的问题。


	JVM内存模型:
	在java中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指
	实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java语言规范称之为formal method 
	parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，
	也不受内存模型的影响。

	
    2.重排序：
		在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：
		1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
		2. 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。
		如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
		3. 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。
		上述的1属于编译器重排序，2和3属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编
	译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序
	，JMM的处
		理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory 
		barriers，intel称之为memory fence）
		指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。
		JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理
		器重排序，为程序员提供一致的内存可见性保证。


		
	3.synchronized关键字
		1.synchronized关键字取得的锁都是对象锁，哪个线程先执行带synchronized关键字的方法，哪个线程就持有该方法所
	属对象的锁Lock，那么其他线程只能呈等待状态，前提是多个线程访问的是同一个对象。
		2.synchronized关键字修饰的方法相当于synchronized(this).锁的是当前对象。
		3.只有共享资源的读写才需要同步化，如果不是共享资源，那么根本就没有同步的必要。
		4.如果A线程先持有object对象的Lock锁，B线程可以以异步的方式调用object对象中的非synchronized类型的方法。
		5.如果A线程先持有object对象的Lock锁，B线程如果在这时调用object对象中的synchronized类型的方法，则需要
	等待。
		6.脏读一定会出现在操作实例变量的情况下，这就是不同线程“争抢”实例变量的结果。
		7.子类可以通过“可重入锁”调用父类的同步方法。即子类的synchronized方法中，可以调用父类的synchronized方法。
		8.当一个线程执行的代码出现异常时，其所持有的锁会自动释放。
		9.死锁：线程A持有锁一，申请锁二；同时线程B持有锁二，申请锁一。就会出现死锁现象。
		10.同步synchronized不仅可以解决一个线程看到对象处于不一致的状态，还可以保证进入同步方法或者同步代码块的每
	个线程，都看到由同一个锁保护之前所有的修改效果。




	4.对64位的变量long和double的写操作不具有原子性。



	5.happens-before规则
		程序顺序规则：一个线程中的每个操作，happens- before于该线程中的任意后续操作。
		监视器锁规则：对一个监视器锁的解锁，happens- before于随后对这个监视器锁的加锁。
		volatile变量规则：对一个volatile域的写，happens- before于任意后续对这个volatile域的读。
		传递性：如果A happens- before B，且B happens- before C，那么A happens- before C。


		
	6.公平锁和非公平锁的内存语义做个总结：
		1.公平锁和非公平锁释放时，最后都要写一个volatile变量state。
		2.公平锁获取时，首先会去读这个volatile变量。
		3.非公平锁获取时，首先会用CAS更新这个volatile变量,这个操作同时具有volatile读和volatile写的内存语义。


		
	7.Java多线程同步机制的根本原理：
		1.利用volatile变量的写-读所具有的内存语义。
		2.利用CAS所附带的volatile读和volatile写的内存语义。

		
	8.由于java的CAS同时具有volatile读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式：
		1.A线程写volatile变量，随后B线程读这个volatile变量。
		2.A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
		3.A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
		4.A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。
		
	

		
	9.结束线程
		在线程类中定义一个volatile的boolean型变量，同时定义该变量的set方法。在run方法中判断该boolean变量的值，决
	定线程是否继续执行。如果要停止线程，则在线程外将该boolean变量的值设为false。


	10.util包下面有原子类。原子类是原子操作可用的类型，它可以在没有锁的情况下做到线程安全。原子类也不是完全安全的
，它能够保证结果正确，但不能保证执行顺序正确。

	

	
	线程间通信：
	1.线程间通信的主要方法：
		1.使用wait/notify实现线程间的通信；
		2.生产者/消费者模式的实现；
		3.join方法的使用；
		4.ThreadLocal类的使用；


	ReentrantLock类的使用：
		监视器类:Condition。
		Object的wait方法，相当于Condition的await()方法。
		Object的notify方法，相当于Condition的signal()方法。
		Object的notifyAll方法，相当于Condition的signalAll()方法。

		Condition可以创建多个，对某一单独的线程使用单独的Condition，因此可以唤醒特定的线程。
		synchronized关键字没有此用法。
	
	
	spring的bean的生命周期：
		1.singleton(默认值)；当一个bean的作用域被设置成singleton，那么该bean容器中只会存在一个共享的bean实例。
		2.prototype：每一次请求(将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法)都会产生一个新的
	bean的实例。需要注意的是，spring不能对prototype类型的bean的整个生命周期负责，创建完prototype类型的bean之后
	spring容器就不再对该bean进行管理。清除prototype作用域的对象并释放任何prototype 
	bean所持有的昂贵资源，都是客户端代码的职责。
		3.request：针对每次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTPrequest内有效。
		4.session：session作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTPsession内
	有效。
		5.global session:global session作用域类似于标准的HTTPsession作用域。在global
	session作用域中定义的bean被限定于全局portlet Session的生命周期范围内。如果你在web中使用global 
	session作用域来标识bean，那么web会自动当成session类型来使用。
		6.自定义bean的作用域。待研究。。。。
		说明：定义request，session，global session类型的作用域需要加一个ContextListener。
		<listener-class>org.springframework.web.context.request.RequestContextListener</listener-class>


多线程并发工具类：
	1.CountDownLatch
	CountDownLatch相当于一个计数器，它通过构造方法设置一个数字参数。当有一个线程调用它的countdown方法时参数减一，
然后调用它的await方法使当前线程进入阻塞状态。当数字参数被减到0的时候，所有被阻塞的线程都会被唤醒。当然，也可以调
用带时间参数的await方法。使当前线程只阻塞一定的时间。


	2.CyclicBarrier
	循环屏障，可以代替CountDownLatch。它可以让一组线程到达一个屏障(同步点)时被阻塞，直到最后一个线程到达屏障时，
屏障才会开门所有被屏障拦截的线程才会继续执行。每个被阻塞的线程通过调用CyclicBarrier的await方法，来告诉
CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。CyclicBarrier通过构造方法来设定被阻塞线程的个数。与
CountDownLatch不同的是，CyclicBarrier可以通过构造方法指定，当所有线程到达屏障时，优先执行哪一个线程。或者先执行一
个别的其他线程。另外，CyclicBarrier可以通过reset方法重置。


	3.Semaphore
	Semaphore是用来控制线程执行数量的辅助工具。它允许一定数量的线程同时执行(例如100)。
	当这一定数量的线程中有一个执行完，它将允许别的线程代替执行完的线程的位置。

	4.Exchanger
	用于线程间传递数据的工具类。两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先
执行exchange方法，它会一直等待第二个线程也执行exchange方法。当两个线程都到达同步点时，两个线程就会交换exchange
方法里面的参数，将参数作为数据传递给对方。

线程池技术ThreadPoolExecutor(自己总结的)：
	1.线程池中有两个List类型的成员变量。因为会有多线程操作，所以要保证是线程安全的。其中一个List变量里面保存的是
用来执行任务的线程，称为workList；另一个变量里面保存的是将要被执行的任务，称为jobList。workList中所有的worker都
是一个线程。每个线程挨个从jobList里面取出job并执行期run方法。切记，是执行job的run方法，不是start方法。

	2.若线程池中任务已满，会执行RejectedExecutionHandler接口中的rejectedExecution方法。这个handler可以自己实现，
默认的实现是抛出一个RejectedExecutionException异常。

	3.线程池中的worker执行若出现错误，会运行ThreadPoolExecutor中的afterExecute(Runnable r, Throwable t)方法，该
方法默认是没有语句的可以继承ThreadPoolExecutor类，并重写该方法。

	阻塞
	1.在任何时候线程必须停下来等待它没有的资源时，就会发生阻塞。常见的阻塞有阻塞于I/O，阻塞于锁。
	2.特别注意，阻塞的线程，不会释放任何线程已经拥有的锁。对于I/O阻塞，不是个大问题，因为I/O最终总会不再阻塞，
线程将继续执行；但是阻塞于锁就不一样，如果一个线程等待第二个线程拥有的锁，而第二个线程等待第一个线程拥有的锁，
就会死锁。

	放弃
	线程可以通过调用Thread.yield()静态方法来放弃CPU使用权。但是！！！放弃并不会释放线程所拥有的锁。

	休眠
	注意！！！休眠的线程还拥有它获得的所有锁。因此，其他需要相同锁的线程会阻塞。所以要尽量避免在同步方法或块内让
线程休眠。





	《实战JAVA高并发程序设计》
	1.并发级别大致可以分为阻塞、无饥饿、无障碍、无锁、无等待几种。

	阻塞：
	一个线程是阻塞的，那么在其他线程释放资源之前，当前线程无法继续执行。当我们使用synchronized关键字，
或者重入锁的时候，我们得到的就是阻塞线程。
	无饥饿：
	如果线程之间是有优先级的，那么线程调度的时候总是会倾向于满足高优先级的线程。也就是说，对于同一个
资源的分配是不公平的。对于非公平的锁来说，系统允许高优先级的线程插队。这样有可能导致低优先级线程产生
饥饿。但如果锁是公平的，满足先来后到，那么饥饿就不会产生，不管新来的线程优先级多高，要想获得资源，就
必须乖乖排队。那么所有的线程都有机会执行。
	无障碍：
	无障碍是一种最弱的非阻塞调度。两个线程如果是无障碍的执行，那么他们不会因为临界区的问题导致一方被
挂起。
	无锁：
	无锁的并行都是无障碍的。在无锁的情况下，所有的线程都能尝试对临界区进行访问，但不同的是，无锁的并发
保证必然有一个线程能够在有限步内完成操作离开临界区。
	在无锁的调用中，一个典型的特点是可能会包含一个无穷循环，在这个循环中，线程会不断尝试改变共享变量。
如果没有冲突，修改成功，那么程序退出，否则继续尝试修改，但无论如何，无锁的并行总能保证有一个线程是可以
胜出的，不至于全军覆没。至于临界区中竞争失败的线程，它们则必须不断重试，直到自己获胜。如果运气很不好，
总是尝试不成功，则会出现类似饥饿的现象，线程会停止不前。
	无等待：
	无等待要求所有线程都必须在有限步内完成，这样就不会引起饥饿问题。
	
	
	什么是CAS
	CAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、
要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都
不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最
新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，
永远都不可能成功。

 
	
	unsafe类的objectFieldOffset方法，计算成员变量的偏移量(其实就是找到该成员变量的内存地址)。
	再通过compareAndSwap方法进行线程同步。
	
	
	
	锁的类型：
	乐观锁：
	乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据
的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间
别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作(比较跟上
一次的版本号，如果一样则更新)，如果失败则要重复读-比较-写的操作。

	悲观锁：
	悲观锁是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候
都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据
就会block直到拿到锁。Java中的悲观锁就是Synchronized，AQS框架下的锁则是先尝
试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。

	线程阻塞的代价：
	Java线程是映射到操作系统原生线程之上的，如果要阻塞或唤醒一个线程就需要
操作系统介入，需要在用户态与内核态之间切换，这种切换会消耗大量的系统资源，
因为用户态与内核态都有各自专用的内存空间，专用的寄存器等，用户态切换至内核
态需要传递给许多变量，参数给内核，内核也需要保护好用户态在切换时的一些寄存
器值、变量等，以便内核态调用结束后切换回用户态继续工作。
	1.如果线程状态切换时一个高频操作时，这将会消耗很多CPU处理时间。
	2.如果对于那些需要同步的简单的代码块，获取锁挂起操作消耗的时间比用户代码
执行的时间还长，这种同步策略显然非常糟糕。
	synchronized会导致争用不到锁的线程进入阻塞状态，所以说它是java语言中一个
重量级的同步操作，被称为重量级锁，为了缓解上述性能问题，从JVM1.5开始。引入了
轻量锁与偏向锁，默认启用了自旋锁，他们都属于乐观锁。

	markword：
	博客地址：http://blog.csdn.net/zqz_zqz/article/details/70233767
	markword是java对象数据结构中的一部分，markword数据的长度在32位和64位的
虚拟机中分别为32bit和64bit，它的最后2bit是锁状态标志位。
	
	自旋锁：
	自旋锁的原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么
那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，
它们只需要等一等(自旋)，等持有锁的线程释放锁后即可立即获取锁，这样就避免
用户线程和内核的切换的消耗。
	但是线程自旋是需要消耗CPU的，说白了就是让cpu在做无用功，线程不能一直
占用cpu自旋做无用功，所以需要设定一个自旋等待的最大时间。
	如果持有锁的线程执行的时间超过自旋等待的最大时间仍没有释放锁，就会导
致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋
进入阻塞状态。
	自旋锁的优缺点：
	自旋锁的目的是为了占着CPU资源不释放，等到获取到锁立即进行处理。但是
如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态
占用CPU资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要。
	JVM对于自旋周期的选择，JDK1.6开始引入了适应性自旋锁，自旋的时间不再是
固定的，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定。
	自旋锁的开启：
	JDK1.6中 -XX:+UseSpinning开启；
	JDK1.7后，去掉参数，由jvm控制。
	
	偏向锁：
	Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。
	偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，
同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要出发同
步的，这种情况下，就会给线程加一个偏向锁。
	如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，
JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。

	轻量级锁：
	轻量级锁是由偏向锁升级而来，偏向锁运行在一个线程进入同步块的情况下，
当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。
	等待轻量锁的线程不会阻塞，它会一直自旋等待锁，并如上所说修改markword。
	如果自旋也没有获取到锁，则使用重量级锁，没有获取到锁的线程阻塞挂起，
直到持有锁的线程执行完同步块唤醒他们。
	
	锁优化：
	以上介绍的锁不是我们代码中能够控制的，但是借鉴上面的思想，我们可以
优化我们自己线程的加锁操作；
	1.减少锁的时间
	不需要同步执行的代码，能不放在同步块里面执行就不要放在同步块内，可以
让锁尽快释放；
	2.减少锁的粒度
	它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁
竞争。
	ConcurrentHashMap
	java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment数组。
	Segment继承自ReenTrantLock，所以每个Segment就是一个可重入锁，每个Segment
有一个HashEntry<K,V>数组用来存放数据，put操作时，先确定往哪个Segment放数据，
只需要锁定这个Segment，执行put，其它的Segment不会被锁定，所以数组中有多少
个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。
	LinkedBlockingQueue
	LinkedBlockingQueue也体现了这样的思想，在队列头入队，在队列尾出队，
入队和出队使用不同的锁，相对于LinkedBlockingArray只有一个锁效率要高；
	锁的粒度不能无限拆，最多可以将一个锁拆为当前cpu数量个锁即可；
	
	
	锁粗化：
	大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度；
	在以下场景下需要粗化锁的粒度：
	假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则
每次进出循环，都进出一次临界区，效率是非常差的。

	使用读写锁
	ReentranReadWriteLock是一个读写锁，读操作加读锁，可以并发读，写操作
使用写锁，只能单线程写。

	